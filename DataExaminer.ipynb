{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import IsolationForest \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "from sklearn import decomposition\n",
    "import  matplotlib.pylab as plt\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free parameters that we get to choose \n",
    "percent_train = .95                      # training / testing split\n",
    "file_path = 'data/expanded_pratik.csv'   # file to work with \n",
    "top_k_features = 15                      # number of features to keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data set and print some information out about the data that we are looking at \n",
    "# DATA FILE \n",
    "#  - expanded_shalaka_logical_firefox.csv (2234431, 16555)\n",
    "#  - expanded_pratik.csv (1442460, 6696)\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.keys()[1:])\n",
    "print('\\n\\n')\n",
    "print('# of features: ' + str(len(df.keys())-1))\n",
    "print('\\n\\n')\n",
    "print(df.head())\n",
    "print('\\n\\n')\n",
    "print('Normal Samples: ' + str(len(np.where(df['label'] == 'NORMAL')[0])))\n",
    "print('Attack Samples: ' + str(len(np.where(df['label'] == 'Attack_3a')[0])))\n",
    "print('\\n\\n')\n",
    "print(np.unique(df['label']))\n",
    "feature_names = df.keys()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the data to a new dataframe and relabel the data [NORMAL = 0, ATTACK = 0]\n",
    "df2 = df.copy()\n",
    "df2['label'][np.where(df2['label'] == 'NORMAL')[0]] = 0\n",
    "df2['label'][np.where(df2['label'] == 'Attack_3a')[0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df2.values\n",
    "X = data[:, 1:]\n",
    "y = data[:, 0]\n",
    "\n",
    "good_samples = np.where(y==0)[0]\n",
    "bad_samples = np.where(y==1)[0]\n",
    "new_indx = np.concatenate((good_samples[:50000], bad_samples))\n",
    "Xnew = X[new_indx, :]\n",
    "ynew = y[new_indx]\n",
    "\n",
    "mi_scores = mutual_info_classif(Xnew, ynew, n_neighbors = 5)\n",
    "feature_ranks = np.argsort(mi_scores)[::-1][:top_k_features]\n",
    "print('Feature Ranks')\n",
    "p = 0\n",
    "for i in feature_ranks:\n",
    "    print('(' + str(p) + '): ' + feature_names[i] + ' (' + str(mi_scores[i]) + ')')\n",
    "    p += 1\n",
    "#len(ynew)\n",
    "keep_features = feature_ranks[:top_k_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a training and testing data file\n",
    "tr_data_path = file_path[:-4] + '_TRAIN.pkl'\n",
    "te_data_path = file_path[:-4] + '_TEST.pkl'\n",
    "tr_stop = int(np.floor(percent_train*len(df2)))\n",
    "\n",
    "# rearrange the data\n",
    "all_data = df2.values\n",
    "good = np.where(y==0)[0]\n",
    "malicious = np.where(y==1)[0]\n",
    "all_data_sorted = np.concatenate((all_data[good, :], all_data[malicious, :]), axis=0)\n",
    "\n",
    "data_tr = all_data_sorted[:tr_stop]\n",
    "X = data_tr[:, 1:]\n",
    "y = data_tr[:, 0]\n",
    "data = {'X': X, 'y': y, 'features': keep_features}\n",
    "outfile = open(tr_data_path, 'wb')\n",
    "pickle.dump(data, outfile)\n",
    "outfile.close()\n",
    "print('Training Samples: ' + str(len(y)))\n",
    "\n",
    "data_te = all_data_sorted[tr_stop:]\n",
    "X = data_te[:, 1:]\n",
    "y = data_te[:, 0]\n",
    "\n",
    "\n",
    "data = {'X': X, 'y': y, 'features': keep_features}\n",
    "outfile = open(te_data_path, 'wb')\n",
    "pickle.dump(data, outfile)\n",
    "outfile.close()\n",
    "print('Testing Samples: ' + str(len(y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
